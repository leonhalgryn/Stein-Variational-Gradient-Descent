
<!-- SECTION 1 Stein's method -->

@article{muller_ipm,
 ISSN = {00018678},
 URL = {http://www.jstor.org/stable/1428011},
 abstract = {We consider probability metrics of the following type: for a class F of functions and probability measures P, Q we define $d_{\germ{F}}(P,\ Q)\coloneq \text{sup}_{f\in \germ{F}}|\int f\,dP-\int f\,dQ|$. A unified study of such integral probability metrics is given. We characterize the maximal class of functions that generates such a metric. Further, we show how some interesting properties of these probability metrics arise directly from conditions on the generating class of functions. The results are illustrated by several examples, including the Kolmogorov metric, the Dudley metric and the stop-loss metric.},
 author = {Alfred Müller},
 journal = {Advances in Applied Probability},
 number = {2},
 pages = {429--443},
 publisher = {Applied Probability Trust},
 title = {Integral Probability Metrics and Their Generating Classes of Functions},
 urldate = {2023-09-27},
 volume = {29},
 year = {1997}
}

@article{gretton_ipm,
  title={{On integral probability metrics, $\phi$-divergences and binary classification}},
  author={Bharath K. Sriperumbudur and Kenji Fukumizu and Arthur Gretton and Bernhard Scholkopf and Gert R. G. Lanckriet},
  journal={arXiv: Information Theory},
  year={2009},
  url={https://api.semanticscholar.org/CorpusID:14114329}
}

@misc{gretton_ipm_old,
      title={On integral probability metrics, $\phi$-divergences and binary classification}, 
      author={Bharath K. Sriperumbudur and Kenji Fukumizu and Arthur Gretton and Bernhard Schölkopf and Gert R. G. Lanckriet},
      year={2009},
      eprint={0901.2698},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

@article{ley_approx_expectations,
  title={Approximate Computation of Expectations: the Canonical Stein Operator},
  author={Christophe Ley and Gesine Reinert and Yvik Swan},
  journal={Research Papers in Economics},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:118846588}
}

@article{ley_approx_expectations_old,
author = {Ley, Christophe and Reinert, Gesine and Swan, Yvik},
year = {2014},
month = {08},
pages = {},
title = {Approximate computation of expectations : a canonical Stein operator }
}

@article{ross_stein_fundamentals,
      title={Fundamentals of Stein's method}, 
      author={Nathan Ross},
      journal={Probability Surveys},
      volume={8},
      year={2011},
      pages={210–293},
      issn={1549-5787},
      doi={10.1214/11-PS182},
      eprint={1109.1880},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}


@inproceedings{reinert_couplings,
  author    = {G. Reinert},
  title     = {Couplings for Normal Approximations with Stein's Method},
  booktitle = {Microsurveys in Discrete Probability},
  editor    = {D. Aldous and J. Propp},
  year      = {1998},
  pages     = {193--207},
  publisher = {AMS},
  series    = {Dimacs series},
  url       = {https://www.stats.ox.ac.uk/~reinert/papers/steinrevrev.pdf},
}

@article{hu_stein_neural_sampler,
  title={{Stein Neural Sampler}},
  author={Tianyang Hu and Zixiang Chen and Hanxi Sun and Jincheng Bai and Mao Ye and Guang Cheng},
  journal={ArXiv},
  year={2021},
  volume={abs/1810.03545},
  url={https://api.semanticscholar.org/CorpusID:52938806}
}

@misc{hu_stein_neural_sampler_old,
      title={Stein Neural Sampler}, 
      author={Tianyang Hu and Zixiang Chen and Hanxi Sun and Jincheng Bai and Mao Ye and Guang Cheng},
      year={2021},
      eprint={1810.03545},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{stein1972,
      title={A Bound for the Error in the Normal Approximation to the Distribution of a Sum of Dependent Random Variables},
      author={Charles Stein},
      booktitle={Proceedings of the Sixth Berkeley Symposium on Mathematical Statistics and Probability},
      year={1972},
      pages={583-602},
url={https://api.semanticscholar.org/CorpusID:53492374}
}


@inproceedings{stein1972_old,
  title={A bound for the error in the normal approximation to the distribution of a sum of dependent random variables},
  author={Charles M. Stein},
  year={1972},
  url={https://api.semanticscholar.org/CorpusID:53492374}
}

@article{chen_steins_method,
    title={{Stein's method of normal approximation: Some recollections and reflections}},
    author={Louis H. Y. Chen},
    journal={The Annals of Statistics},
    year={2021},
    volume={49},
    number={4},
    pages={1850–1863},
    doi={10.1214/21-AOS2083},
    note={© Institute of Mathematical Statistics, 2021},
    eprint={2104.08302},
    archivePrefix={arXiv},
    primaryClass={math.PR}
}




@article{anastasiou_stein,
author = {Andreas Anastasiou and Alessandro Barp and Fran{\c{c}}ois-Xavier Briol and Bruno Ebner and Robert E. Gaunt and Fatemeh Ghaderinezhad and Jackson Gorham and Arthur Gretton and Christophe Ley and Qiang Liu and Lester Mackey and Chris J. Oates and Gesine Reinert and Yvik Swan},
title = {{Stein’s Method Meets Computational Statistics: A Review of Some Recent Developments}},
volume = {38},
journal = {Statistical Science},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {120 -- 139},
keywords = {approximate Markov chain Monte Carlo, control variates, goodness-of-fit testing, likelihood ratio, maximum likelihood estimator, prior sensitivity, sample quality, Stein’s method, variational inference},
year = {2023},
doi = {10.1214/22-STS863},
URL = {https://doi.org/10.1214/22-STS863}
}

@article{gorham_sample_quality,
    title={Measuring Sample Quality with Diffusions},
    author={Jackson Gorham and Andrew B. Duncan and Sebastian J. Vollmer and Lester Mackey},
    journal={The Annals of Applied Probability},
    year={2019},
    volume={29},
    number={5},
    pages={2884–2928},
    doi={10.1214/19-AAP1467},
    note={© Institute of Mathematical Statistics, 2019},
    eprint={1611.06972},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}



@article{gaunt_algebra_stein,
title = {An algebra of Stein operators},
journal = {Journal of Mathematical Analysis and Applications},
volume = {469},
number = {1},
pages = {260-279},
year = {2019},
issn = {0022-247X},
doi = {https://doi.org/10.1016/j.jmaa.2018.09.015},
url = {https://www.sciencedirect.com/science/article/pii/S0022247X1830756X},
author = {Robert E. Gaunt and Guillaume Mijoule and Yvik Swan},
keywords = {Stein's method, Stein operators, Product distributions, Variance-gamma distribution},
abstract = {We build upon recent advances on the distributional aspect of Stein's method to propose a novel and flexible technique for computing Stein operators for random variables that can be written as products of independent random variables. We show that our results are valid for a wide class of distributions including normal, beta, variance-gamma, generalized gamma and many more. Our operators are kth degree differential operators with polynomial coefficients; they are straightforward to obtain even when the target density bears no explicit handle. As an application, we derive a new formula for the density of the product of k independent symmetric variance-gamma distributed random variables.}
}

@article{ley_steins_method,
    title={Stein's method for comparison of univariate distributions},
    author={Christophe Ley and Gesine Reinert and Yvik Swan},
    journal={Probability Surveys},
    year={2017},
    volume={14},
    pages={1–52},
    issn={1549-5787},
    doi={10.1214/16-PS278},
    eprint={1408.2998},
    archivePrefix={arXiv},
    primaryClass={math.PR}
}

@misc{ley_steins_method_old,
      title={Stein's method for comparison of univariate distributions}, 
      author={Christophe Ley and Gesine Reinert and Yvik Swan},
      year={2016},
      eprint={1408.2998},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@article{mijoule_stein_2019,
author = {G. Mijoule and M. Raič and G. Reinert and Y. Swan},
title = {{Stein’s density method for multivariate continuous distributions}},
volume = {28},
journal = {Electronic Journal of Probability},
number = {none},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {1 -- 40},
keywords = {density method, elliptical distributions, Stein kernels, Stein operators},
year = {2023},
doi = {10.1214/22-EJP883},
URL = {https://doi.org/10.1214/22-EJP883}
}


@misc{mijoule_stein_2019_old,
      title={Stein operators, kernels and discrepancies for multivariate continuous distributions}, 
      author={Guillaume Mijoule and Gesine Reinert and Yvik Swan},
      year={2019},
      eprint={1806.03478},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@article{chatterjee_survey,
  title={{A short survey of Stein's method}},
  author={Sourav Chatterjee},
  journal={arXiv: Probability},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:118347930}
}


@misc{gorham_sample_quality_2019,
      title={Measuring Sample Quality with Stein's Method}, 
      author={Jackson Gorham and Lester Mackey},
      year={2019},
      eprint={1506.03039},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@book{rice_textbook,
  title={Mathematical Statistics and Data Analysis},
  author={Rice, John A.},
  year={2007},
  edition={3rd},
  publisher={Cengage Learning}
}

@inproceedings{gorham_sample_quality_2015,
author = {Gorham, Jackson and Mackey, Lester},
title = {{Measuring Sample Quality with Stein's Method}},
year = {2015},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 1},
pages = {226–234},
numpages = {9},
location = {Montreal, Canada},
series = {NIPS'15}
}


@article{ley_canonical_stein_operator,
author = {Ley, Christophe and Reinert, Gesine and Swan, Yvik},
year = {2014},
month = {08},
pages = {},
title = {Approximate computation of expectations : a canonical Stein operator}
}

@article{bonis_normal_bounds,
author = {Bonis, Thomas},
year = {2020},
month = {12},
pages = {},
title = {{Stein’s method for normal approximation in Wasserstein distances with application to the multivariate central limit theorem}},
volume = {178},
journal = {Probability Theory and Related Fields},
doi = {10.1007/s00440-020-00989-4}
}


@article{barbour_generator,
  author    = {A. D. Barbour},
  title     = {Stein's method for diffusion approximations},
  journal   = {Probability Theory and Related Fields},
  year      = {1990},
  volume    = {84},
  number    = {3},
  pages     = {297--322},
  doi       = {10.1007/BF01197887},
  issn      = {1432-2064},
  url       = {https://doi.org/10.1007/BF01197887},
}


<!-- =========================================================================================== -->


<!-- SECTION 2 Stein Discrepancy -->

@inproceedings{gorham_stochastic_sd,
 author = {Gorham, Jackson and Raj, Anant and Mackey, Lester},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {17931--17942},
 publisher = {Curran Associates, Inc.},
 title = {Stochastic Stein Discrepancies},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/d03a857a23b5285736c4d55e0bb067c8-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{ley_swan_density,
    title={Stein's density approach and information inequalities},
    author={Christophe Ley and Yvik Swan},
    journal={Electronic Communications in Probability},
    year={2013},
    volume={18},
    number={7},
    pages={1–14},
    doi={10.1214/ECP.v18-2578},
    issn={1083-589X},
    eprint={1210.3921},
    archivePrefix={arXiv},
    primaryClass={math.PR}
}


@misc{ley_swan_density_old,
      title={Stein's density approach and information inequalities}, 
      author={Christophe Ley and Yvik Swan},
      year={2013},
      eprint={1210.3921},
      archivePrefix={arXiv},
      primaryClass={math.PR}
}

@inproceedings{gong_sliced_ksd,
    title={{Sliced Kernelized Stein Discrepancy}},
    author={Wenbo Gong and Yingzhen Li and José Miguel Hernández-Lobato},
    booktitle={International Conference on Learning Representations (ICLR)},
    year={2021},
    url={https://openreview.net/forum?id=1jDFcof5P9v},
    note={Published as a conference paper at ICLR 2021},
    eprint={2006.16531},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{stein_exchangeable_2004,
 ISSN = {07492170},
 URL = {http://www.jstor.org/stable/4356331},
 abstract = {The method of exchangeable pairs has emerged as an important tool in proving limit theorems for Poisson, normal and other classical approximations. Here the method is used in a simulation context. We estimate transition probabilitites from the simulations and use these to reduce variances. Exchangeable pairs are used as control variates. Finally, a general approximation theorem is developed that can be complemented by simulations to provide actual estimates of approximation errors.},
 author = {Charles Stein and Persi Diaconis and Susan Holmes and Gesine Reinert},
 journal = {Lecture Notes-Monograph Series},
 pages = {1--26},
 publisher = {Institute of Mathematical Statistics},
 title = {Use of Exchangeable Pairs in the Analysis of Simulations},
 urldate = {2023-09-09},
 volume = {46},
 year = {2004}
}

@misc{liu_wild_vi,
      title={Two Methods For Wild Variational Inference}, 
      author={Qiang Liu and Yihao Feng},
      year={2017},
      eprint={1612.00081},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://openreview.net/forum?id=Sy4tzwqxe}
}



@article{barp_min_ksd,
      title={{Minimum Stein Discrepancy Estimators}}, 
      author={Alessandro Barp and Francois-Xavier Briol and Andrew B. Duncan and Mark Girolami and Lester Mackey},
      year={2022},
      eprint={1906.08283},
      archivePrefix={arXiv},
      primaryClass={math.ST},
	journal={Proceedings of the 33rd Conference on Neural Information Processing Systems}
}





<!-- =========================================================================================== -->


<!-- SECTION 3 Kernelised Stein Discrepancy -->

@article{hoeffding_u_statistics,
author = {Wassily Hoeffding},
title = {{A Class of Statistics with Asymptotically Normal Distribution}},
volume = {19},
journal = {The Annals of Mathematical Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {293 -- 325},
year = {1948},
doi = {10.1214/aoms/1177730196},
URL = {https://doi.org/10.1214/aoms/1177730196}
}


@article{hyvarinen_score,
  author  = {Aapo Hyv{{\"a}}rinen},
  title   = {Estimation of Non-Normalized Statistical Models by Score Matching},
  journal = {Journal of Machine Learning Research},
  year    = {2005},
  volume  = {6},
  number  = {24},
  pages   = {695--709},
  url     = {http://jmlr.org/papers/v6/hyvarinen05a.html}
}

@article{south_tail_2022,
	doi = {10.1146/annurev-statistics-040220-091727},
  
	url = {https://doi.org/10.1146%2Fannurev-statistics-040220-091727},
  
	year = 2022,
	month = {mar},
  
	publisher = {Annual Reviews},
  
	volume = {9},
  
	number = {1},
  
	pages = {529--555},
  
	author = {Leah F. South and Marina Riabiz and Onur Teymur and Chris J. Oates},
  
	title = {Postprocessing of {MCMC}
},
  
	journal = {Annual Review of Statistics and Its Application}
}

@article{oates_control_2016,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/44681807},
 author = {Chris J. Oates and Mark Girolami and Nicolas Chopin},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {3},
 pages = {695--718},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {{Control functionals for Monte Carlo integration}},
 urldate = {2023-10-19},
 volume = {79},
 year = {2017}
}

@misc{oates_control_2016_old,
      title={Control functionals for Monte Carlo integration}, 
      author={Chris J. Oates and Mark Girolami and Nicolas Chopin},
      year={2016},
      eprint={1410.2392},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}


@InProceedings{liu_ksd,
  title = 	 {{A Kernelized Stein Discrepancy for Goodness-of-fit Tests}},
  author = 	 {Liu, Qiang and Lee, Jason and Jordan, Michael},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {276--284},
  year = 	 {2016},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/liub16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/liub16.html}
}


@misc{liu_KSD_old,
      title={A Kernelized Stein Discrepancy for Goodness-of-fit Tests and Model Evaluation}, 
      author={Qiang Liu and Jason D. Lee and Michael I. Jordan},
      year={2016},
      eprint={1602.03253},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@article{chwialkowski_ksd,
  title = 	 {A Kernel Test of Goodness of Fit},
  author = 	 {Chwialkowski, Kacper and Strathmann, Heiko and Gretton, Arthur},
  journal = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2606--2615},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/chwialkowski16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/chwialkowski16.html},
  abstract = 	 {We propose a nonparametric statistical test for goodness-of-fit: given a set of samples, the test determines how likely it is that these were generated from a target density function. The measure of goodness-of-fit is a divergence constructed via Stein’s method using functions from a Reproducing Kernel Hilbert Space. Our test statistic is based on an empirical estimate of this divergence, taking the form of a V-statistic in terms of the log gradients of the target density and the kernel. We derive a statistical test, both for i.i.d. and non-i.i.d. samples, where we estimate the null distribution quantiles using a wild bootstrap procedure. We apply our test to quantifying convergence of approximate Markov Chain Monte Carlo methods, statistical model criticism, and evaluating quality of fit vs model complexity in nonparametric density estimation.}
}


@article{ghojogh_rkhs,
  title={{Reproducing Kernel Hilbert Space, Mercer's Theorem, Eigenfunctions, Nystr{\"o}m Method, and Use of Kernels in Machine Learning: Tutorial and Survey}},
  author={Benyamin Ghojogh and Ali Ghodsi and Fakhri Karray and Mark Crowley},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.08443},
  url={https://api.semanticscholar.org/CorpusID:235446387}
}



@article{kanagawa_ksd,
	doi = {10.1093/jrsssb/qkad050},
  
	url = {https://doi.org/10.1093%2Fjrsssb%2Fqkad050},
  
	year = 2023,
	month = {may},
  
	publisher = {Oxford University Press ({OUP})},
  
	volume = {85},
  
	number = {3},
  
	pages = {986--1011},
  
	author = {Heishiro Kanagawa and Wittawat Jitkrittum and Lester Mackey and Kenji Fukumizu and Arthur Gretton},
  
	title = {{A kernel Stein test for comparing latent variable models}},
  
	journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology}
}


<!-- =========================================================================================== -->


<!-- SECTION 5  SVGD-->

@article{liu_svgd_moment,
      title={Stein Variational Gradient Descent as Moment Matching}, 
      author={Qiang Liu and Dilin Wang},
      journal={Proceedings of the 32nd Conference on Neural Information Processing Systems (NeurIPS 2018)},
      address={Montréal, Canada},
      year={2018},
      eprint={1810.11693},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@misc{liu_svgd_moment_old,
      title={Stein Variational Gradient Descent as Moment Matching}, 
      author={Qiang Liu and Dilin Wang},
      year={2018},
      eprint={1810.11693},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@article{blei_vi_review,
	doi = {10.1080/01621459.2017.1285773},
  
	url = {https://doi.org/10.1080%2F01621459.2017.1285773},
  
	year = 2017,
	month = {apr},
  
	publisher = {Informa {UK} Limited},
  
	volume = {112},
  
	number = {518},
  
	pages = {859--877},
  
	author = {David M. Blei and Alp Kucukelbir and Jon D. McAuliffe},
  
	title = {Variational Inference: A Review for Statisticians},
  
	journal = {Journal of the American Statistical Association}
}

@inproceedings{liu_svgd,
  title={Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm},
  author={Qiang Liu and Dilin Wang},
  year={2016},
  booktitle={Proceedings of the 30th Conference on Neural Information Processing Systems (NIPS 2016)},
  address={Barcelona, Spain},
  eprint={1608.04471},
  archivePrefix={arXiv},
  primaryClass={stat.ML},
  url={https://arxiv.org/abs/1608.04471}
}

@article{papamak_vi,
  author  = {George Papamakarios and Eric Nalisnick and Danilo Jimenez Rezende and Shakir Mohamed and Balaji Lakshminarayanan},
  title   = {Normalizing Flows for Probabilistic Modeling and Inference},
  journal = {Journal of Machine Learning Research},
  year    = {2021},
  volume  = {22},
  number  = {57},
  pages   = {1--64},
  url     = {http://jmlr.org/papers/v22/19-1028.html}
}

@inproceedings{liu_svgd_theory,
  title={Stein Variational Gradient Descent: Theory and Applications},
  author={Qiang Liu},
  year={2016},
  url={https://api.semanticscholar.org/CorpusID:14946786}
}


<!-- =========================================================================================== -->


<!-- SVGD EXTENSIONS AND IMPROVEMENTS-->
@article{wang_svgd_matrix_kernel,
      title={{Stein Variational Gradient Descent with Matrix-Valued Kernels}},
      author={Dilin Wang and Ziyang Tang and Chandrajit Bajaj and Qiang Liu},
      journal={Advances in Neural Information Processing Systems},
      year={2019},
      volume={32},
      pages={7834--7844}
}


@misc{wang_svgd_matrix_kernel_old,
      title={Stein Variational Gradient Descent With Matrix-Valued Kernels}, 
      author={Dilin Wang and Ziyang Tang and Chandrajit Bajaj and Qiang Liu},
      year={2019},
      eprint={1910.12794},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


@inproceedings{han_discrete_svgd,
  title = 	 {Stein Variational Inference for Discrete Distributions},
  author =       {Han, Jun and Ding, Fan and Liu, Xianglong and Torresani, Lorenzo and Peng, Jian and Liu, Qiang},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {4563--4572},
  year = 	 {2020},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/han20c/han20c.pdf},
  url = 	 {https://proceedings.mlr.press/v108/han20c.html}
}



@inproceedings{chen_projected_svgd,
 author = {Chen, Peng and Ghattas, Omar},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {1947--1958},
 publisher = {Curran Associates, Inc.},
 title = {Projected Stein Variational Gradient Descent},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/14faf969228fc18fcd4fcf59437b0c97-Paper.pdf},
 volume = {33},
 year = {2020}
}


@InProceedings{liu_grassman_svgd,
  title = 	 {{Grassmann Stein Variational Gradient Descent}},
  author =       {Liu, Xing and Zhu, Harrison and Ton, Jean-Francois and Wynne, George and Duncan, Andrew},
  booktitle = 	 {Proceedings of The 25th International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2002--2021},
  year = 	 {2022},
  volume = 	 {151},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {28--30 Mar},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v151/liu22a/liu22a.pdf},
  url = 	 {https://proceedings.mlr.press/v151/liu22a.html}
}



@misc{liu_grassman_svgd_old,
      title={Grassmann Stein Variational Gradient Descent}, 
      author={Xing Liu and Harrison Zhu and Jean-François Ton and George Wynne and Andrew Duncan},
      year={2022},
      eprint={2202.03297},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@inproceedings{zhuo_mp_svgd,
  title={{Message Passing Stein Variational Gradient Descent}},
  author={Jingwei Zhuo and Chang Liu and Jiaxin Shi and Jun Zhu and Ning Chen and Bo Zhang},
  booktitle={International Conference on Machine Learning},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:51877948}
}

@misc{zhuo_mp_svgd_old,
      title={{Message Passing Stein Variational Gradient Descent}}, 
      author={Jingwei Zhuo and Chang Liu and Jiaxin Shi and Jun Zhu and Ning Chen and Bo Zhang},
      year={2018},
      eprint={1711.04425},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}



@misc{zhou_aump_svgd,
      title={Augmented Message Passing Stein Variational Gradient Descent}, 
      author={Jiankui Zhou and Yue Qiu},
      year={2023},
      eprint={2305.10636},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{dangelo_annealed_svgd,
  title={{Annealed Stein Variational Gradient Descent}},
  author={Francesco D'Angelo and Vincent Fortuin},
  journal={Proceedings of the 3rd Symposium on Advances in Approximate Bayesian Inference},
  year={2021},
  pages={1--12},
  eprint={2101.09815},
  archivePrefix={arXiv},
  primaryClass={cs.LG}
}


@article{detommaso_svn,
      title={{A Stein variational Newton method}}, 
      author={Gianluca Detommaso and Tiangang Cui and Alessio Spantini and Youssef Marzouk and Robert Scheichl},
      year={2018},
      eprint={1806.03085},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
	journal = {Advances in Neural Information Processing Systems (NIPS) 2018}
}

@inproceedings{liu_riemann_svgd,
  title={{Riemannian Stein Variational Gradient Descent for Bayesian Inference}},
  author={Chang Liu and Jun Zhu},
  booktitle={AAAI Conference on Artificial Intelligence},
  year={2017},
  url={https://api.semanticscholar.org/CorpusID:19150312}
}

@misc{liu_riemann_svgd_old,
      title={Riemannian Stein Variational Gradient Descent for Bayesian Inference}, 
      author={Chang Liu and Jun Zhu},
      year={2017},
      eprint={1711.11216},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{ai_mk_svgd,
	doi = {10.1007/s12559-022-10069-5},
  
	url = {https://doi.org/10.1007%2Fs12559-022-10069-5},
  
	year = 2022,
	month = {nov},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {15},
  
	number = {2},
  
	pages = {672--682},
  
	author = {Qingzhong Ai and Shiyu Liu and Lirong He and Zenglin Xu},
  
	title = {Stein Variational Gradient Descent with Multiple Kernels},
  
	journal = {Cognitive Computation}
}



@inproceedings{han_gf_svgd,
  title = 	 {Stein Variational Gradient Descent Without Gradient},
  author =       {Han, Jun and Liu, Qiang},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1900--1908},
  year = 	 {2018},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/han18b/han18b.pdf},
  url = 	 {https://proceedings.mlr.press/v80/han18b.html}
}


@misc{han_gf_svgd_old,
      title={Stein Variational Gradient Descent Without Gradient}, 
      author={Jun Han and Qiang Liu},
      year={2018},
      eprint={1806.02775},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{dangelo_stein_nn_ensembles,
  title={{On Stein Variational Neural Network Ensembles}},
  author={Francesco D'Angelo and Vincent Fortuin and F. Wenzel},
  journal={ArXiv},
  year={2021},
  volume={abs/2106.10760},
  url={https://api.semanticscholar.org/CorpusID:235490493}
}




<!-- =========================================================================================== -->

<!-- SVGD APPLICATIONS -->

@article{wang_svgd_gan,
  title={{Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent}},
  author={Wang, D. and Qin, X. and Song, F. and Cheng, L.},
  journal={IEEE Transactions on Neural Networks and Learning Systems},
  year={2022},
  volume={33},
  number={7},
  pages={2768-2780},
  doi={10.1109/TNNLS.2020.3045082}
}


@misc{wang_svgd_gan_old,
      title={Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent}, 
      author={Dong Wang and Xiaoqian Qin and Fengyi Song and Li Cheng},
      year={2020},
      eprint={2004.10495},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{pu_svgd_vae,
      title={VAE Learning via Stein Variational Gradient Descent}, 
      author={Yunchen Pu and Zhe Gan and Ricardo Henao and Chunyuan Li and Shaobo Han and Lawrence Carin},
      year={2017},
      eprint={1704.05155},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      journal={Proceedings of the 31st Conference on Neural Information Processing Systems (NIPS 2017)},
      address={Long Beach, CA, USA}
}



@misc{pu_svgd_vae_old,
      title={VAE Learning via Stein Variational Gradient Descent}, 
      author={Yunchen Pu and Zhe Gan and Ricardo Henao and Chunyuan Li and Shaobo Han and Lawrence Carin},
      year={2017},
      eprint={1704.05155},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


<!-- =========================================================================================== -->


<!-- SVGD CONVERGENCE-->

@article{shi_finite_convergence,
  title={{A Finite-Particle Convergence Rate for Stein Variational Gradient Descent}},
  author={Jiaxin Shi and Lester W. Mackey},
  journal={ArXiv},
  year={2022},
  volume={abs/2211.09721},
  url={https://api.semanticscholar.org/CorpusID:253581833}
}

@misc{shi_finite_convergence_old,
      title={A Finite-Particle Convergence Rate for Stein Variational Gradient Descent}, 
      author={Jiaxin Shi and Lester Mackey},
      year={2023},
      eprint={2211.09721},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@InProceedings{salim_convergence,
  title = 	 {{A Convergence Theory for SVGD in the Population Limit under Talagrand’s Inequality T1}},
  author =       {Salim, Adil and Sun, Lukang and Richtarik, Peter},
  booktitle = 	 {Proceedings of the 39th International Conference on Machine Learning},
  pages = 	 {19139--19152},
  year = 	 {2022},
  volume = 	 {162},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {17--23 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v162/salim22a/salim22a.pdf},
  url = 	 {https://proceedings.mlr.press/v162/salim22a.html},
}


@misc{salim_convergence_old,
      title={A Convergence Theory for SVGD in the Population Limit under Talagrand's Inequality T1}, 
      author={Adil Salim and Lukang Sun and Peter Richtárik},
      year={2022},
      eprint={2106.03076},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{bl_weak_convergence,
	doi = {10.1214/10-aop616},
  
	url = {https://doi.org/10.1214%2F10-aop616},
  
	year = 2012,
	month = {jan},
  
	publisher = {Institute of Mathematical Statistics},
  
	volume = {40},
  
	number = {1},
  
	author = {Amarjit Budhiraja and Paul Dupuis and Markus Fischer},
  
	title = {Large deviation properties of weakly interacting processes via weak convergence methods},
  
	journal = {The Annals of Probability}
}

@article{lunde_bl_weak,
  title={Sample splitting and weak assumption inference for time series},
   author={Robert Lunde},
  journal={arXiv preprint arXiv:1902.07425},
  year={2019},
eprint={1902.07425},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}


@misc{lunde_bl_weak_old,
      title={Sample Splitting and Weak Assumption Inference For Time Series}, 
      author={Robert Lunde},
      year={2019},
      eprint={1902.07425},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}

@article{osti_kl_weak,
title = {Kullback--Leibler Approximation for Probability Measures on Infinite Dimensional Spaces},
author = {Pinski, Frank J. and Simpson, G. and Stuart, A. M. and Weber, Hendrik},
abstractNote = {In a variety of applications it is important to extract information from a probability measure μ on an infinite dimensional space. Examples include the Bayesian approach to inverse problems and (possibly conditioned) continuous time Markov processes. It may then be of interest to find a measure ν, from within a simple class of measures, which approximates μ. Here, this problem is studied in the case where the Kullback–Leibler divergence is employed to measure the quality of the approximation. A calculus of variations viewpoint is adopted, and the particular case where ν is chosen from the set of Gaussian measures is studied in detail. Basic existence and uniqueness theorems are established, together with properties of minimizing sequences. Furthermore, parameterization of the class of Gaussians through the mean and inverse covariance is introduced, the need for regularization is explained, and a regularized minimization is studied in detail. The calculus of variations framework resulting from this work provides the appropriate underpinning for computational algorithms.},
doi = {10.1137/140962802},
url = {https://www.osti.gov/biblio/1459163}, journal = {SIAM Journal of Mathematical Analysis},
issn = {0036-1410},
number = 6,
volume = 47,
place = {United States},
year = {2015},
month = {11}
}

@article{walker_kl_weak,
   title={{New approaches to Bayesian consistency}},
   volume={32},
   ISSN={0090-5364},
   url={http://dx.doi.org/10.1214/009053604000000409},
   DOI={10.1214/009053604000000409},
   number={5},
   journal={The Annals of Statistics},
   publisher={Institute of Mathematical Statistics},
   author={Walker, Stephen},
   year={2004},
   month={Oct} }

@article{lu_svgd_scaling,
author = {Lu, Jianfeng and Lu, Yulong and Nolen, James},
title = {{Scaling Limit of the Stein Variational Gradient Descent: The Mean Field Regime}},
journal = {SIAM Journal on Mathematical Analysis},
volume = {51},
number = {2},
pages = {648-671},
year = {2019},
doi = {10.1137/18M1187611},
URL = { 
   https://doi.org/10.1137/18M1187611
},
eprint = {     
https://doi.org/10.1137/18M1187611
}
}




@misc{lu_svgd_scaling_old,
      title={Scaling limit of the Stein variational gradient descent: the mean field regime}, 
      author={Jianfeng Lu and Yulong Lu and James Nolen},
      year={2018},
      eprint={1805.04035},
      archivePrefix={arXiv},
      primaryClass={math.AP}
}


<!-- =========================================================================================== -->


<!-- CHAPTER 3  ADVANTAGES AND LIMITATIONS -->

@article{kirkpatrick_sa,
author = {Kirkpatrick, S and Gelatt, C and Vecchi, M},
year = {1983},
month = {01},
pages = {671-680},
title = {Optimization by simulated annealing},
journal = {Science 200(2548)}
}

@article{ting_isolation_kernel,
  title={Breaking the curse of dimensionality with Isolation Kernel},
  author={Kai Ming Ting and Takashi Washio and Ye Zhu and Yang Xu},
  journal={ArXiv},
  year={2021},
  volume={abs/2109.14198},
  url={https://api.semanticscholar.org/CorpusID:238215563}
}

@misc{ting_isolation_kernel_old,
      title={Breaking the curse of dimensionality with Isolation Kernel}, 
      author={Kai Ming Ting and Takashi Washio and Ye Zhu and Yang Xu},
      year={2021},
      eprint={2109.14198},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{spigler_cod,
	doi = {10.1088/1742-5468/abc61d},
  
	url = {https://doi.org/10.1088%2F1742-5468%2Fabc61d},
  
	year = 2020,
	month = {dec},
  
	publisher = {{IOP} Publishing},
  
	volume = {2020},
  
	number = {12},
  
	pages = {124001},
  
	author = {Stefano Spigler and Mario Geiger and Matthieu Wyart},
  
	title = {Asymptotic learning curves of kernel methods: empirical data versus teacher{\textendash}student paradigm},
  
	journal = {Journal of Statistical Mechanics: Theory and Experiment}
}

@inproceedings{ye_stein_self_repulsive,
 author = {Ye, Mao and Ren, Tongzheng and Liu, Qiang},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {241--252},
 publisher = {Curran Associates, Inc.},
 title = {Stein Self-Repulsive Dynamics: Benefits From Past Samples},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/023d0a5671efd29e80b4deef8262e297-Paper.pdf},
 volume = {33},
 year = {2020}
}


@misc{ye_stein_self_repulsive_old,
      title={Stein Self-Repulsive Dynamics: Benefits From Past Samples}, 
      author={Mao Ye and Tongzheng Ren and Qiang Liu},
      year={2020},
      eprint={2002.09070},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{fan_stein_filtering,
      title={Stein particle filtering}, 
      author={Jiaojiao Fan and Amirhossein Taghvaei and Yongxin Chen},
      year={2021},
      eprint={2106.10568},
      archivePrefix={arXiv},
      primaryClass={cs.CE},
	url = {https://arxiv.org/abs/2106.10568},
	journal      = {CoRR},
  volume       = {abs/2106.10568}
}

@article{li_particle_degeneracy,
	doi = {10.1016/j.eswa.2013.12.031},
  
	url = {https://doi.org/10.1016%2Fj.eswa.2013.12.031},
  
	year = 2014,
	month = {jun},
  
	publisher = {Elsevier {BV}
},
  
	volume = {41},
  
	number = {8},
  
	pages = {3944--3954},
  
	author = {Tiancheng Li and Shudong Sun and Tariq Pervez Sattar and Juan Manuel Corchado},
  
	title = {Fight sample degeneracy and impoverishment in particle filters: A review of intelligent approaches},
  
	journal = {Expert Systems with Applications}
}

@inproceedings{ba_variance_collapse,
title={Understanding the Variance Collapse of {SVGD} in High Dimensions},
author={Jimmy Ba and Murat A Erdogdu and Marzyeh Ghassemi and Shengyang Sun and Taiji Suzuki and Denny Wu and Tianzong Zhang},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=Qycd9j5Qp9J}
}

@article{das_fast,
    title={{Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation}},
    author={Aniket Das and Dheeraj Nagaraj},
    journal={Proceedings of the 37th Conference on Neural Information Processing Systems (NeurIPS 2023)},
    year={2023},
    eprint={2305.17558},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@article{pinder_stein_gp,
  title={{Stein Variational Gaussian Processes}},
  author={Thomas Pinder and Christopher Nemeth and David Leslie},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.12141},
  url={https://api.semanticscholar.org/CorpusID:221949365}
}

@misc{pinder_stein_gp_old,
      title={Stein Variational Gaussian Processes}, 
      author={Thomas Pinder and Christopher Nemeth and David Leslie},
      year={2022},
      eprint={2009.12141},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{robert_mcmc,
author = {Robert, Christian and Elvira, Víctor and Tawn, Nick and Wu, Changye},
year = {2018},
month = {04},
pages = {},
title = {{Accelerating MCMC algorithms}},
volume = {10},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
doi = {10.1002/wics.1435}
}

@misc{robert_mcmc_old,
      title={Accelerating MCMC Algorithms}, 
      author={Christian P. Robert and Victor Elvira and Nick Tawn and Changye Wu},
      year={2018},
      eprint={1804.02719},
      archivePrefix={arXiv},
      primaryClass={stat.CO}
}

@inproceedings{kingma_vi_mcmc,
      title={Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}, 
      author={Tim Salimans and Diederik P. Kingma and Max Welling},
      booktitle={Proceedings of the 32nd International Conference on Machine Learning},
      year={2015},
      address={Lille, France},
      volume={37},
      series={JMLR: W\&CP},
      eprint={1410.6460},
      archivePrefix={arXiv},
      primaryClass={stat.CO}
}


@inproceedings{kingma_vi_mcmc_new,
  title={{Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}},
  author={Tim Salimans and Diederik P. Kingma and Max Welling},
  booktitle={International Conference on Machine Learning},
  year={2014},
  url={https://api.semanticscholar.org/CorpusID:216078910}
}

@misc{kingma_vi_mcmc_old,
      title={Markov Chain Monte Carlo and Variational Inference: Bridging the Gap}, 
      author={Tim Salimans and Diederik P. Kingma and Max Welling},
      year={2015},
      eprint={1410.6460},
      archivePrefix={arXiv},
      primaryClass={stat.CO}
}

@article{zhang_vi_advances,
  title={{Advances in Variational Inference}},
  author={Zhang, Cheng and Butepage, Judith and Kjellstrom, Hedvig and Mandt, Stephan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2019},
  volume={41},
  number={8},
  pages={2008--2026},
  doi={10.1109/TPAMI.2018.2889774}
}


@misc{zhang_vi_advances_old,
      title={Advances in Variational Inference}, 
      author={Cheng Zhang and Judith Butepage and Hedvig Kjellstrom and Stephan Mandt},
      year={2018},
      eprint={1711.05597},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{luengo_mcmc_survey,
	doi = {10.1186/s13634-020-00675-6},
  
	url = {https://doi.org/10.1186%2Fs13634-020-00675-6},
  
	year = 2020,
	month = {may},
  
	publisher = {Springer Science and Business Media {LLC}
},
  
	volume = {2020},
  
	number = {1},
  
	author = {David Luengo and Luca Martino and M{\'{o}}nica Bugallo and V{\'{\i}}ctor Elvira and Simo Särkkä},
  
	title = {A survey of Monte Carlo methods for parameter estimation},
  
	journal = {{EURASIP} Journal on Advances in Signal Processing}
}


@article{ganguly_vi_intro,
      title={An Introduction to Variational Inference}, 
      author={Ankush Ganguly and Samuel W. F. Earp},
      year={2021},
	journal={ArXiv},
      eprint={2108.13083},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
	volume={abs/2108.13083},
	url={https://api.semanticscholar.org/CorpusID:237353445},

}

@article{gunapti_vi_mcmc,
	doi = {10.1017/pasa.2021.64},
  
	url = {https://doi.org/10.1017%2Fpasa.2021.64},
  
	year = 2022,
	publisher = {Cambridge University Press ({CUP})},
  
	volume = {39},
  
	author = {Geetakrishnasai Gunapati and Anirudh Jain and P. K. Srijith and Shantanu Desai},
  
	title = {Variational inference as an alternative to {MCMC} for parameter estimation and model selection},
  
	journal = {Publications of the Astronomical Society of Australia}
}

@article{yan_svgd_local,
	doi = {10.1016/j.cma.2021.114087},
  
	url = {https://doi.org/10.1016%2Fj.cma.2021.114087},
  
	year = 2021,
	month = {dec},
  
	publisher = {Elsevier {BV}
},
  
	volume = {386},
  
	pages = {114087},
  
	author = {Liang Yan and Tao Zhou},
  
	title = {Stein variational gradient descent with local approximations},
  
	journal = {Computer Methods in Applied Mechanics and Engineering}
}

@inproceedings{ke_mode_seeking,
  title={{Imitation Learning as f-Divergence Minimization}},
  author={Liyiming Ke and Matt Barnes and Wen Sun and Gilwoo Lee and Sanjiban Choudhury and Siddhartha S. Srinivasa},
  booktitle={Workshop on the Algorithmic Foundations of Robotics},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:170079195}
}

@misc{ke_mode_seeking_old,
      title={Imitation Learning as $f$-Divergence Minimization}, 
      author={Liyiming Ke and Sanjiban Choudhury and Matt Barnes and Wen Sun and Gilwoo Lee and Siddhartha Srinivasa},
      year={2020},
      eprint={1905.12888},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{huszar_mode_seeking,
  title={{How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?}},
  author={Ferenc Husz{\'a}r},
  journal={ArXiv},
  year={2015},
  volume={abs/1511.05101},
  url={https://api.semanticscholar.org/CorpusID:17206794}
}

@misc{huszar_mode_seeking_old,
      title={How (not) to Train your Generative Model: Scheduled Sampling, Likelihood, Adversary?}, 
      author={Ferenc Huszár},
      year={2015},
      eprint={1511.05101},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

<!-- =========================================================================================== -->


<!-- SECTION 5 Gradient Flow -->
@inproceedings{liu_svgd_gf,
 author = {Liu, Qiang},
 booktitle = {Advances in Neural Information Processing Systems},
 publisher = {Curran Associates, Inc.},
 title = {{Stein Variational Gradient Descent as Gradient Flow}},
 url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/17ed8abedc255908be746d245e50263a-Paper.pdf},
 volume = {30},
 year = {2017}
}


@misc{liu_svgd_gf_old,
      title={Stein Variational Gradient Descent as Gradient Flow}, 
      author={Qiang Liu},
      year={2017},
      eprint={1704.07520},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}


<!-- =========================================================================================== -->



<!-- SECTION 6 SVPG -->

@article{chan_mode_seeking,
author = {Chan, Alan and Silva, Hugo and Lim, Sungsu and Kozuno, Tadashi and Mahmood, A. Rupam and White, Martha},
title = {{Greedification Operators for Policy Optimization: Investigating Forward and Reverse KL Divergences}},
year = {2022},
issue_date = {January 2022},
publisher = {JMLR.org},
volume = {23},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = {jan},
articleno = {253},
numpages = {79},
keywords = {reinforcement learning, policy iteration, policy gradient, kl divergence}
}

@article{liu_svpg,
  title={{Stein Variational Policy Gradient}},
  author={Yang Liu and Prajit Ramachandran and Qiang Liu and Jian Peng},
  journal={ArXiv},
  year={2017},
  volume={abs/1704.02399},
  url={https://api.semanticscholar.org/CorpusID:4410100}
}

@misc{liu_svpg_old,
      title={Stein Variational Policy Gradient}, 
      author={Yang Liu and Prajit Ramachandran and Qiang Liu and Jian Peng},
      year={2017},
      eprint={1704.02399},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{kim_bayesian_maml,
 author = {Yoon, Jaesik and Kim, Taesup and Dia, Ousmane and Kim, Sungwoong and Bengio, Yoshua and Ahn, Sungjin},
 booktitle = {Advances in Neural Information Processing Systems},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Bayesian Model-Agnostic Meta-Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2018/file/e1021d43911ca2c1845910d84f40aeae-Paper.pdf},
 volume = {31},
 year = {2018}
}


@misc{kim_bayesian_maml_old,
      title={Bayesian Model-Agnostic Meta-Learning}, 
      author={Taesup Kim and Jaesik Yoon and Ousmane Dia and Sungwoong Kim and Yoshua Bengio and Sungjin Ahn},
      year={2018},
      eprint={1806.03836},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}


@Article{long_function_approx,
author = {Long , Jihao and Han , Jiequn},
title = {{Reinforcement Learning with Function Approximation: From Linear to Nonlinear}},
journal = {Journal of Machine Learning},
year = {2023},
volume = {2},
number = {3},
pages = {161--193},
issn = {2790-2048},
doi = {https://doi.org/10.4208/jml.230105},
url = {http://global-sci.org/intro/article_detail/jml/22011.html}
}

@misc{long_function_approx_old,
      title={Reinforcement Learning with Function Approximation: From Linear to Nonlinear}, 
      author={Jihao Long and Jiequn Han},
      year={2023},
      eprint={2302.09703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{sb,
  title = {Reinforcement Learning: An Introduction},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2017},
  edition = {Second},
  note = {In progress, Complete Draft},
  month = {November},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts, London, England},
  series = {A Bradford Book}
}

@inproceedings{sutton_policy_gradient,
 author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
 url = {https://proceedings.neurips.cc/paper_files/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
 volume = {12},
 year = {1999}
}

@article{peters_policy_gradients,
author = {Peters, Jan},
year = {2010},
month = {01},
pages = {3698},
title = {Policy gradient methods},
volume = {5},
journal = {Scholarpedia},
doi = {10.4249/scholarpedia.3698}
}


@InProceedings{mnih_asynchronous,
  title = 	 {Asynchronous Methods for Deep Reinforcement Learning},
  author = 	 {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1928--1937},
  year = 	 {2016},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/mniha16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/mniha16.html}
}


@misc{mnih_asynchronous_old,
      title={Asynchronous Methods for Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Adrià Puigdomènech Badia and Mehdi Mirza and Alex Graves and Timothy P. Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
      year={2016},
      eprint={1602.01783},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{weng_pg_blog,
  title   = "Policy Gradient Algorithms",
  author  = "Weng, Lilian",
  journal = "lilianweng.github.io",
  year    = "2018",
  url     = "https://lilianweng.github.io/posts/2018-04-08-policy-gradient/"
}

@article{williams_reinforce,
  title={Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
  author={Ronald J. Williams},
  journal={Machine Learning},
  year={2004},
  volume={8},
  pages={229-256},
  url={https://api.semanticscholar.org/CorpusID:19115634}
}

@article{cohen_exploration, 
title={Diverse Exploration via Conjugate Policies for Policy Gradient Methods},
 volume={33}, 
url={https://ojs.aaai.org/index.php/AAAI/article/view/4215}, 
DOI={10.1609/aaai.v33i01.33013404},
number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Cohen, Andrew and Qiao, Xingye and Yu, Lei and Way, Elliot and Tong, Xiangrong}, 
year={2019}, 
month={Jul.}, 
pages={3404-3411}
 }

@article{weng_exploration,
	doi = {10.1016/j.inffus.2022.03.003},
  
	url = {https://doi.org/10.1016%2Fj.inffus.2022.03.003},
  
	year = 2022,
	month = {sep},
  
	publisher = {Elsevier {BV}
},
  
	volume = {85},
  
	pages = {1--22},
  
	author = {Pawel Ladosz and Lilian Weng and Minwoo Kim and Hyondong Oh},
  
	title = {Exploration in deep reinforcement learning: A survey},
  
	journal = {Information Fusion}
}

@article{levine_max_entropy,
      title={{Maximum Entropy RL (Provably) Solves Some Robust RL Problems}}, 
      author={Benjamin Eysenbach and Sergey Levine},
      year={2022},
      eprint={2103.06257},
      archivePrefix={arXiv},
	journal={International Conference on Learning Representations},
      primaryClass={cs.LG},
	url={https://openreview.net/forum?id=PtSAD3caaA2}
}




@misc{openai_gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}


<!-- OTHER -->

@article{kingma_adam,
  title={{Adam: A Method for Stochastic Optimization}},
  author={Diederik P. Kingma and Jimmy Ba},
  journal={CoRR},
  year={2014},
  volume={abs/1412.6980},
  url={https://api.semanticscholar.org/CorpusID:6628106}
}

@article{hoffman_nuts,
author = {Hoffman, Matthew and Gelman, Andrew},
year = {2011},
month = {11},
pages = {},
title = {{The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian
Monte Carlo}},
volume = {15},
journal = {Journal of Machine Learning Research}
}

@article{duane_hmc,
title = {{Hybrid Monte Carlo}},
journal = {Physics Letters B},
volume = {195},
number = {2},
pages = {216-222},
year = {1987},
issn = {0370-2693},
doi = {https://doi.org/10.1016/0370-2693(87)91197-X},
url = {https://www.sciencedirect.com/science/article/pii/037026938791197X},
author = {Simon Duane and A.D. Kennedy and Brian J. Pendleton and Duncan Roweth},
abstract = {We present a new method for the numerical simulation of lattice field theory. A hybrid (molecular dynamics/Langevin) algorithm is used to guide a Monte Carlo simulation. There are no discretization errors even for large step sizes. The method is especially efficient for systems such as quantum chromodynamics which contain fermionic degrees of freedom. Detailed results are presented for four-dimensional compact quantum electrodynamics including the dynamical effects of electrons.}
}

@misc{tensorflow,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015},
}